{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    OpenAI.api_key = openai_api_key\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVファイルを読み込む\n",
    "idol_list = pd.read_csv('../../data/master/idolname_20240829.csv', encoding='utf-8')\n",
    "\n",
    "# 'idol_group_name'カラムのテキストをリスト化し、欠損値を空文字に置換\n",
    "texts = idol_list['idol_group_name'].fillna('').tolist()\n",
    "\n",
    "# OpenAI APIを使ってテキストをエンベディング\n",
    "def get_embedding(text, model='text-embedding-3-small'):\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            model=model,\n",
    "            input=[text]  # テキストセグメントをリストに変換\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# レート制限を考慮して、各テキストに対してエンベディングを取得\n",
    "embeddings = []\n",
    "for text in texts:\n",
    "    embedding = get_embedding(text)\n",
    "    if embedding is not None:\n",
    "        embeddings.append(embedding)\n",
    "    else:\n",
    "        embeddings.append([0]*1536)  # エンベディングサイズに合わせてゼロベクトルを挿入\n",
    "    time.sleep(0.1)  # レート制限を避けるために待機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idol_list[\"embedding\"]=embeddings\n",
    "idol_list.to_csv('../../data/master/idolname_embedding.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_l2(X,dim):\n",
    "    X = np.array(X)[:,:dim]\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    # ノルムがゼロの要素を特定\n",
    "    zero_norms = (norms == 0)\n",
    "    # ゼロ除算を防ぐためにノルムがゼロの要素を1に置換\n",
    "    norms[zero_norms] = 1\n",
    "    # 各ベクトルを対応するノルムで割る\n",
    "    X_normalized = X / norms\n",
    "    # 元のノルムがゼロだったベクトルを元のままに戻す\n",
    "    X_normalized[zero_norms.flatten()] = X[zero_norms.flatten()]\n",
    "    return X_normalized\n",
    "\n",
    "cut_dim = embeddings\n",
    "norm_dim = normalize_l2(cut_dim,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6010, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idolname_embedding_data = pd.DataFrame(norm_dim,index=texts)#100次元\n",
    "idolname_embedding_data.index.name = \"idol_group_name\"\n",
    "idolname_embedding_data.to_csv('../../data/master/idolname_embedding_data.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
